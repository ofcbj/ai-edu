{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 東京家賃予測 - Deep Learning モデル訓練\n",
    "\n",
    "このノートブックでは、東京の家賃データを使用してディープラーニングモデルを訓練します。\n",
    "\n",
    "## 訓練の流れ\n",
    "1. データ読み込みと前処理\n",
    "2. モデルの作成（基本モデルとAttentionモデル）\n",
    "3. モデルの訓練\n",
    "4. モデルの評価と比較\n",
    "5. 基本的な可視化"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. ライブラリのインポート"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 日本語フォント設定\n",
    "from rent_utils import setup_japanese_font\n",
    "setup_japanese_font()\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(\"✅ 日本語フォント設定完了\")\n",
    "\n",
    "import pandas as pd\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# カスタムモジュール\n",
    "from rent_dl_data import RentDataPreprocessor, TokyoRentDataset\n",
    "from rent_dl_models import RentPredictionNet, RentPredictionNetWithAttention\n",
    "from rent_dl_train import train_model, evaluate_model\n",
    "from rent_config import DEVICE\n",
    "\n",
    "print(f\"Device: {DEVICE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. データ読み込みと前処理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データ読み込み\n",
    "df = pd.read_csv('tokyo_rent_data_v2.csv')\n",
    "print(f\"データ数: {len(df)}\")\n",
    "print(f\"\\nデータの先頭:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データ前処理\n",
    "preprocessor = RentDataPreprocessor()\n",
    "df_processed = preprocessor.fit_transform(df)\n",
    "\n",
    "print(\"前処理完了!\")\n",
    "print(f\"区の数: {preprocessor.num_wards}\")\n",
    "print(f\"建物構造の種類: {len(preprocessor.label_encoders['建物構造'].classes_)}\")\n",
    "print(f\"建物タイプの種類: {len(preprocessor.label_encoders['建物タイプ'].classes_)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 特徴量とターゲットの分離\n",
    "feature_cols = ['区_encoded', '建物構造_encoded', '建物タイプ_encoded',\n",
    "                '部屋サイズ_m2', '駅距離_分', '築年数_年', '区_avg_price']\n",
    "\n",
    "X = df_processed[feature_cols].values\n",
    "y = df['家賃_円'].values / 10000  # 1万円単位にスケール\n",
    "\n",
    "# データ分割 (70/15/15)\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "print(f\"訓練データ: {len(X_train)}\")\n",
    "print(f\"検証データ: {len(X_val)}\")\n",
    "print(f\"テストデータ: {len(X_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataLoaderの作成\n",
    "train_dataset = TokyoRentDataset(X_train, y_train)\n",
    "val_dataset = TokyoRentDataset(X_val, y_val)\n",
    "test_dataset = TokyoRentDataset(X_test, y_test)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "print(\"DataLoader作成完了!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. モデルの作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# モデルパラメータ\n",
    "num_wards = len(preprocessor.label_encoders['区'].classes_)\n",
    "num_structures = len(preprocessor.label_encoders['建物構造'].classes_)\n",
    "num_types = len(preprocessor.label_encoders['建物タイプ'].classes_)\n",
    "\n",
    "print(f\"num_wards: {num_wards}\")\n",
    "print(f\"num_structures: {num_structures}\")\n",
    "print(f\"num_types: {num_types}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 基本モデルの作成\n",
    "model_basic = RentPredictionNet(num_wards, num_structures, num_types).to(DEVICE)\n",
    "\n",
    "total_params = sum(p.numel() for p in model_basic.parameters())\n",
    "print(f\"基本モデル総パラメータ数: {total_params:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attentionモデルの作成\n",
    "model_attention = RentPredictionNetWithAttention(num_wards, num_structures, num_types).to(DEVICE)\n",
    "\n",
    "total_params = sum(p.numel() for p in model_attention.parameters())\n",
    "print(f\"Attentionモデル総パラメータ数: {total_params:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. モデルの訓練"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 基本モデルの訓練\n",
    "print(\"基本モデルを訓練中...\")\n",
    "train_losses_basic, val_losses_basic = train_model(\n",
    "    model_basic, train_loader, val_loader, DEVICE,\n",
    "    num_epochs=50, learning_rate=0.001,\n",
    "    model_save_path='best_rent_model_basic.pth'\n",
    ")\n",
    "\n",
    "print(\"\\n基本モデル訓練完了!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attentionモデルの訓練\n",
    "print(\"Attentionモデルを訓練中...\")\n",
    "train_losses_att, val_losses_att = train_model(\n",
    "    model_attention, train_loader, val_loader, DEVICE,\n",
    "    num_epochs=50, learning_rate=0.001,\n",
    "    model_save_path='best_rent_model_attention.pth'\n",
    ")\n",
    "\n",
    "print(\"\\nAttentionモデル訓練完了!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. モデルの評価"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ベストモデルをロード\n",
    "model_basic.load_state_dict(torch.load('best_rent_model_basic.pth', map_location=DEVICE, weights_only=True))\n",
    "model_attention.load_state_dict(torch.load('best_rent_model_attention.pth', map_location=DEVICE, weights_only=True))\n",
    "\n",
    "print(\"ベストモデルをロードしました\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 基本モデルの評価\n",
    "predictions_basic, actuals_basic, mae_basic, rmse_basic, r2_basic = evaluate_model(\n",
    "    model_basic, test_loader, DEVICE, \"基本モデル\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attentionモデルの評価\n",
    "predictions_att, actuals_att, mae_att, rmse_att, r2_att = evaluate_model(\n",
    "    model_attention, test_loader, DEVICE, \"Attentionモデル\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# モデル比較\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"モデル性能比較\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"{'指標':<15} {'基本モデル':<20} {'Attentionモデル':<20} {'改善率':<15}\")\n",
    "print(\"-\" * 80)\n",
    "print(f\"{'MAE (¥)':<15} {mae_basic:>15,.0f}    {mae_att:>15,.0f}    {(mae_basic-mae_att)/mae_basic*100:>10.2f}%\")\n",
    "print(f\"{'RMSE (¥)':<15} {rmse_basic:>15,.0f}    {rmse_att:>15,.0f}    {(rmse_basic-rmse_att)/rmse_basic*100:>10.2f}%\")\n",
    "print(f\"{'R² Score':<15} {r2_basic:>15.4f}    {r2_att:>15.4f}    {(r2_att-r2_basic)/r2_basic*100:>10.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. 基本的な可視化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 日本語フォント再設定\n",
    "from rent_utils import setup_japanese_font\n",
    "setup_japanese_font()\n",
    "\n",
    "# 訓練曲線と予測結果の可視化\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "\n",
    "# 1. 訓練曲線（基本モデル）\n",
    "axes[0, 0].plot(train_losses_basic, label='Train Loss', alpha=0.7)\n",
    "axes[0, 0].plot(val_losses_basic, label='Validation Loss', alpha=0.7)\n",
    "axes[0, 0].set_xlabel('Epoch')\n",
    "axes[0, 0].set_ylabel('Loss')\n",
    "axes[0, 0].set_title('Training History - Basic Model')\n",
    "axes[0, 0].legend()\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# 2. 訓練曲線（Attentionモデル）\n",
    "axes[0, 1].plot(train_losses_att, label='Train Loss', alpha=0.7)\n",
    "axes[0, 1].plot(val_losses_att, label='Validation Loss', alpha=0.7)\n",
    "axes[0, 1].set_xlabel('Epoch')\n",
    "axes[0, 1].set_ylabel('Loss')\n",
    "axes[0, 1].set_title('Training History - Attention Model')\n",
    "axes[0, 1].legend()\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# 3. 予測 vs 実際（Attentionモデル）\n",
    "axes[1, 0].scatter(actuals_att, predictions_att, alpha=0.5)\n",
    "axes[1, 0].plot([actuals_att.min(), actuals_att.max()],\n",
    "                [actuals_att.min(), actuals_att.max()], 'r--', lw=2)\n",
    "axes[1, 0].set_xlabel('Actual Rent (¥)')\n",
    "axes[1, 0].set_ylabel('Predicted Rent (¥)')\n",
    "axes[1, 0].set_title(f'Predictions vs Actual (R² = {r2_att:.4f})')\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# 4. 残差プロット（Attentionモデル）\n",
    "residuals = actuals_att - predictions_att\n",
    "axes[1, 1].scatter(predictions_att, residuals, alpha=0.5)\n",
    "axes[1, 1].axhline(y=0, color='r', linestyle='--', lw=2)\n",
    "axes[1, 1].set_xlabel('Predicted Rent (¥)')\n",
    "axes[1, 1].set_ylabel('Residuals (¥)')\n",
    "axes[1, 1].set_title('Residual Plot')\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('training_results.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"可視化保存: training_results.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 日本語フォント再設定\n",
    "from rent_utils import setup_japanese_font\n",
    "setup_japanese_font()\n",
    "\n",
    "# 区の埋め込み可視化（Attentionモデル）\n",
    "ward_embeddings = model_attention.ward_embedding.weight.detach().cpu().numpy()\n",
    "ward_names = preprocessor.label_encoders['区'].classes_\n",
    "\n",
    "# PCA 2D投影\n",
    "pca = PCA(n_components=2)\n",
    "ward_embeddings_2d = pca.fit_transform(ward_embeddings)\n",
    "\n",
    "# 区別平均価格で色付け\n",
    "ward_avg_prices = df.groupby('区')['家賃_円'].mean()\n",
    "colors = [ward_avg_prices[ward] for ward in ward_names]\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "scatter = plt.scatter(ward_embeddings_2d[:, 0], ward_embeddings_2d[:, 1],\n",
    "                      c=colors, cmap='RdYlBu_r', s=200, alpha=0.7)\n",
    "\n",
    "# いくつかの区名を表示\n",
    "for i, ward in enumerate(ward_names):\n",
    "    if ward in ['港区', '千代田区', '渋谷区', '新宿区', '足立区', '葛飾区', '江戸川区']:\n",
    "        plt.annotate(ward, (ward_embeddings_2d[i, 0], ward_embeddings_2d[i, 1]),\n",
    "                     fontsize=10, ha='center')\n",
    "\n",
    "plt.xlabel('Embedding Dimension 1')\n",
    "plt.ylabel('Embedding Dimension 2')\n",
    "plt.title('Ward Embeddings Visualization (PCA 2D)', fontsize=14, fontweight='bold')\n",
    "plt.colorbar(scatter, label='Average Rent (¥)')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig('ward_embeddings_2d.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"可視化保存: ward_embeddings_2d.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. モデルとpreprocessorの保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 基本モデルの保存\n",
    "torch.save({\n",
    "    'model_state_dict': model_basic.state_dict(),\n",
    "    'preprocessor': preprocessor,\n",
    "    'model_config': {\n",
    "        'num_wards': num_wards,\n",
    "        'num_structures': num_structures,\n",
    "        'num_types': num_types\n",
    "    }\n",
    "}, 'rent_prediction_model_basic.pth')\n",
    "\n",
    "# Attentionモデルの保存\n",
    "torch.save({\n",
    "    'model_state_dict': model_attention.state_dict(),\n",
    "    'preprocessor': preprocessor,\n",
    "    'model_config': {\n",
    "        'num_wards': num_wards,\n",
    "        'num_structures': num_structures,\n",
    "        'num_types': num_types\n",
    "    }\n",
    "}, 'rent_prediction_model_attention.pth')\n",
    "\n",
    "print(\"モデル保存完了!\")\n",
    "print(\"  - rent_prediction_model_basic.pth\")\n",
    "print(\"  - rent_prediction_model_attention.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 完了!\n",
    "\n",
    "訓練が完了しました。次のノートブックで予測や可視化を行えます:\n",
    "- `rent_dl_predict.ipynb` - 予測と対話型UI\n",
    "- `rent_dl_visualize.ipynb` - 高度な可視化と分析"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_edu",
   "language": "python",
   "name": "env_edu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
