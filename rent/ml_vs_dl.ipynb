{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d98d2b7d-1179-4641-98d9-b9960a30693e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "🎓 機械学習 vs ディープラーニング 教育用統合比較システム\n",
    "東京家賃予測を通じた実践学習教材\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, learning_curve\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# 日本語フォント設定\n",
    "import matplotlib.font_manager as fmt\n",
    "fmt.fontManager.addfont(r'/mnt/c/Windows/Fonts/meiryo.ttc')\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['font.family'] = ['Meiryo']\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "class MLvsDLEducationalSystem:\n",
    "    \"\"\"機械学習とディープラーニングを比較学習する教育システム\"\"\"\n",
    "    \n",
    "    def __init__(self, data_path='tokyo_rent_data_v2.csv'):\n",
    "        \"\"\"初期化およびデータ読み込み\"\"\"\n",
    "        self.df = pd.read_csv(data_path)\n",
    "        self.X_train = None\n",
    "        self.X_test = None\n",
    "        self.y_train = None\n",
    "        self.y_test = None\n",
    "        self.models = {}\n",
    "        self.results = {}\n",
    "        \n",
    "        print(\"=\"*80)\n",
    "        print(\"🎓 機械学習 vs ディープラーニング教育システム\")\n",
    "        print(\"=\"*80)\n",
    "        print(f\"データ読み込み完了: {len(self.df)} サンプル\")\n",
    "        \n",
    "    def lesson_1_data_understanding(self):\n",
    "        \"\"\"レッスン1: データを理解する\"\"\"\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"📚 レッスン1: データを理解する\")\n",
    "        print(\"=\"*80)\n",
    "        \n",
    "        # 1. データ構造の把握\n",
    "        print(\"\\n1️⃣ データ構造:\")\n",
    "        print(f\"   - サンプル数: {len(self.df)}\")\n",
    "        print(f\"   - 特徴量数: {len(self.df.columns) - 1}\")\n",
    "        print(f\"   - ターゲット変数: 家賃_円\")\n",
    "        \n",
    "        # 2. 変数タイプの分析\n",
    "        print(\"\\n2️⃣ 変数タイプ:\")\n",
    "        numeric_features = ['部屋サイズ_m2', '駅距離_分', '築年数_年']\n",
    "        categorical_features = ['区', '建物構造', '建物タイプ']\n",
    "        \n",
    "        print(f\"   📊 数値型変数 ({len(numeric_features)}個):\")\n",
    "        for feat in numeric_features:\n",
    "            print(f\"      - {feat}: 平均={self.df[feat].mean():.2f}, 標準偏差={self.df[feat].std():.2f}\")\n",
    "        \n",
    "        print(f\"\\n   📝 カテゴリ型変数 ({len(categorical_features)}個):\")\n",
    "        for feat in categorical_features:\n",
    "            print(f\"      - {feat}: {self.df[feat].nunique()} カテゴリ\")\n",
    "        \n",
    "        # 3. ターゲット変数の分布\n",
    "        print(\"\\n3️⃣ ターゲット変数の分布:\")\n",
    "        print(f\"   - 平均家賃: ¥{self.df['家賃_円'].mean():,.0f}\")\n",
    "        print(f\"   - 中央値: ¥{self.df['家賃_円'].median():,.0f}\")\n",
    "        print(f\"   - 標準偏差: ¥{self.df['家賃_円'].std():,.0f}\")\n",
    "        print(f\"   - 最小/最大: ¥{self.df['家賃_円'].min():,.0f} ~ ¥{self.df['家賃_円'].max():,.0f}\")\n",
    "        \n",
    "        # 可視化\n",
    "        fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "        \n",
    "        # ターゲット分布\n",
    "        axes[0, 0].hist(self.df['家賃_円'], bins=50, edgecolor='black', alpha=0.7)\n",
    "        axes[0, 0].set_title('ターゲット分布（家賃）')\n",
    "        axes[0, 0].set_xlabel('家賃（円）')\n",
    "        axes[0, 0].set_ylabel('頻度')\n",
    "        \n",
    "        # 数値型変数\n",
    "        for idx, feat in enumerate(numeric_features):\n",
    "            ax = axes[0, idx+1] if idx < 2 else axes[1, idx-2]\n",
    "            ax.scatter(self.df[feat], self.df['家賃_円'], alpha=0.5)\n",
    "            ax.set_xlabel(feat)\n",
    "            ax.set_ylabel('家賃（円）')\n",
    "            ax.set_title(f'{feat} vs 家賃')\n",
    "        \n",
    "        # 区別平均価格\n",
    "        ward_avg = self.df.groupby('区')['家賃_円'].mean().sort_values(ascending=False)[:10]\n",
    "        axes[1, 1].barh(range(len(ward_avg)), ward_avg.values)\n",
    "        axes[1, 1].set_yticks(range(len(ward_avg)))\n",
    "        axes[1, 1].set_yticklabels(ward_avg.index)\n",
    "        axes[1, 1].set_xlabel('平均家賃（円）')\n",
    "        axes[1, 1].set_title('上位10区の平均家賃')\n",
    "        \n",
    "        # 相関関係\n",
    "        corr_matrix = self.df[numeric_features + ['家賃_円']].corr()\n",
    "        sns.heatmap(corr_matrix, annot=True, fmt='.2f', cmap='coolwarm', \n",
    "                    ax=axes[1, 2], square=True)\n",
    "        axes[1, 2].set_title('相関行列')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig('lesson1_data_understanding.png', dpi=150)\n",
    "        plt.show()\n",
    "        \n",
    "        # 重要なインサイト\n",
    "        print(\"\\n💡 重要なインサイト:\")\n",
    "        print(\"   1. 区が価格に大きな影響 → カテゴリ変数の重要性\")\n",
    "        print(\"   2. 部屋サイズと価格の正の相関関係\")\n",
    "        print(\"   3. 駅距離、築年数と価格の負の相関関係\")\n",
    "        print(\"   4. ターゲット分布が右に偏っている → 変換を検討\")\n",
    "        \n",
    "        return self.df\n",
    "    \n",
    "    def lesson_2_preprocessing_comparison(self):\n",
    "        \"\"\"レッスン2: 前処理方法の比較\"\"\"\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"📚 レッスン2: ML vs DL 前処理の違い\")\n",
    "        print(\"=\"*80)\n",
    "        \n",
    "        from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "        \n",
    "        # ML用前処理\n",
    "        print(\"\\n🔧 機械学習の前処理:\")\n",
    "        print(\"   1. One-Hot Encoding: カテゴリ変数をバイナリベクトルに変換\")\n",
    "        print(\"   2. Feature Scaling: StandardScalerで正規化\")\n",
    "        print(\"   3. Feature Engineering: 手動で交互作用項を生成\")\n",
    "        \n",
    "        # One-Hot Encoding\n",
    "        df_ml = pd.get_dummies(self.df, columns=['区', '建物構造', '建物タイプ'])\n",
    "        print(f\"\\n   元の特徴量数: {len(self.df.columns)}\")\n",
    "        print(f\"   One-Hot後: {len(df_ml.columns)}\")\n",
    "        \n",
    "        # DL用前処理\n",
    "        print(\"\\n🧠 ディープラーニングの前処理:\")\n",
    "        print(\"   1. Label Encoding: カテゴリを整数に変換\")\n",
    "        print(\"   2. Embedding Layer: カテゴリを学習可能なベクトルに変換\")\n",
    "        print(\"   3. Automatic Feature Learning: ネットワークが自動的に特徴を学習\")\n",
    "        \n",
    "        # Label Encoding\n",
    "        le = LabelEncoder()\n",
    "        df_dl = self.df.copy()\n",
    "        for col in ['区', '建物構造', '建物タイプ']:\n",
    "            df_dl[f'{col}_encoded'] = le.fit_transform(self.df[col])\n",
    "        \n",
    "        print(f\"\\n   Label Encoding後: 元データ + {3} エンコード列\")\n",
    "        \n",
    "        # 可視化\n",
    "        fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "        \n",
    "        # ML前処理の結果\n",
    "        axes[0].bar(['元データ', 'One-Hot後'], \n",
    "                    [len(self.df.columns), len(df_ml.columns)],\n",
    "                    color=['blue', 'red'])\n",
    "        axes[0].set_ylabel('特徴量数')\n",
    "        axes[0].set_title('ML前処理: 特徴量の爆発')\n",
    "        axes[0].text(1, len(df_ml.columns), f'{len(df_ml.columns)} 特徴量', \n",
    "                     ha='center', va='bottom')\n",
    "        \n",
    "        # DL前処理の結果\n",
    "        embedding_dims = {'区': 16, '建物構造': 4, '建物タイプ': 4}\n",
    "        categories = ['区\\n(23→16)', '構造\\n(4→4)', 'タイプ\\n(4→4)']\n",
    "        original = [23, 4, 4]\n",
    "        embedded = [16, 4, 4]\n",
    "        \n",
    "        x = np.arange(len(categories))\n",
    "        width = 0.35\n",
    "        \n",
    "        bars1 = axes[1].bar(x - width/2, original, width, label='元の次元', color='blue')\n",
    "        bars2 = axes[1].bar(x + width/2, embedded, width, label='埋め込み次元', color='green')\n",
    "        \n",
    "        axes[1].set_xlabel('カテゴリ')\n",
    "        axes[1].set_ylabel('次元数')\n",
    "        axes[1].set_title('DL前処理: 埋め込み次元')\n",
    "        axes[1].set_xticks(x)\n",
    "        axes[1].set_xticklabels(categories)\n",
    "        axes[1].legend()\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig('lesson2_preprocessing.png', dpi=150)\n",
    "        plt.show()\n",
    "        \n",
    "        print(\"\\n💡 重要な違い:\")\n",
    "        print(\"   ML: 高次元疎ベクトル → 計算効率性 ↓\")\n",
    "        print(\"   DL: 低次元密ベクトル → 意味的関係の学習が可能\")\n",
    "        \n",
    "        return df_ml, df_dl\n",
    "    \n",
    "    def lesson_3_model_architecture(self):\n",
    "        \"\"\"レッスン3: モデルアーキテクチャの比較\"\"\"\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"📚 レッスン3: モデルアーキテクチャの比較\")\n",
    "        print(\"=\"*80)\n",
    "        \n",
    "        print(\"\\n🔧 従来の機械学習モデル:\")\n",
    "        ml_models = {\n",
    "            '線形回帰': '線形関係を仮定、解釈容易',\n",
    "            'Ridge/Lasso': 'L2/L1正則化で過学習防止',\n",
    "            'ランダムフォレスト': 'アンサンブル、非線形、特徴量重要度',\n",
    "            '勾配ブースティング': '順次的アンサンブル、高性能'\n",
    "        }\n",
    "        \n",
    "        for model, desc in ml_models.items():\n",
    "            print(f\"   • {model}: {desc}\")\n",
    "        \n",
    "        print(\"\\n🧠 ディープラーニングアーキテクチャ:\")\n",
    "        print(\"   • 入力層: 7特徴量\")\n",
    "        print(\"   • 埋め込み層: カテゴリ変数のベクトル化\")\n",
    "        print(\"   • 隠れ層: 512→256→128 (非線形変換)\")\n",
    "        print(\"   • Attention機構: 動的な重み付け\")\n",
    "        print(\"   • 出力層: 1 (予測値)\")\n",
    "        \n",
    "        # アーキテクチャの複雑さ比較\n",
    "        complexity_data = {\n",
    "            'モデル': ['線形回帰', 'Ridge', 'ランダムフォレスト', 'XGBoost', 'ニューラルネット'],\n",
    "            'パラメータ数': [50, 50, 10000, 5000, 300000],\n",
    "            '学習時間': [1, 1, 10, 20, 100],\n",
    "            '解釈可能性': [10, 10, 6, 4, 2],\n",
    "            '性能': [5, 6, 8, 9, 10]\n",
    "        }\n",
    "        \n",
    "        df_complexity = pd.DataFrame(complexity_data)\n",
    "        \n",
    "        fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "        \n",
    "        # パラメータ数\n",
    "        axes[0, 0].bar(df_complexity['モデル'], df_complexity['パラメータ数'], \n",
    "                       color=['green', 'green', 'blue', 'blue', 'red'])\n",
    "        axes[0, 0].set_ylabel('パラメータ数')\n",
    "        axes[0, 0].set_title('モデルの複雑さ')\n",
    "        axes[0, 0].set_yscale('log')\n",
    "        \n",
    "        # 学習時間\n",
    "        axes[0, 1].bar(df_complexity['モデル'], df_complexity['学習時間'],\n",
    "                       color=['green', 'green', 'blue', 'blue', 'red'])\n",
    "        axes[0, 1].set_ylabel('相対学習時間')\n",
    "        axes[0, 1].set_title('学習効率')\n",
    "        \n",
    "        # 解釈可能性 vs 性能\n",
    "        axes[1, 0].scatter(df_complexity['解釈可能性'], \n",
    "                          df_complexity['性能'], s=200, alpha=0.6)\n",
    "        for i, model in enumerate(df_complexity['モデル']):\n",
    "            axes[1, 0].annotate(model, \n",
    "                               (df_complexity['解釈可能性'][i], \n",
    "                                df_complexity['性能'][i]),\n",
    "                               ha='center', va='center')\n",
    "        axes[1, 0].set_xlabel('解釈可能性')\n",
    "        axes[1, 0].set_ylabel('性能')\n",
    "        axes[1, 0].set_title('トレードオフ: 解釈可能性 vs 性能')\n",
    "        axes[1, 0].grid(True, alpha=0.3)\n",
    "        \n",
    "        # モデル選択ガイド\n",
    "        axes[1, 1].axis('off')\n",
    "        guide_text = \"\"\"\n",
    "        📊 モデル選択ガイド:\n",
    "        \n",
    "        ✅ 線形/Ridge選択時:\n",
    "        • 解釈が重要な場合\n",
    "        • データが少ない場合\n",
    "        • 高速な学習が必要な場合\n",
    "        \n",
    "        ✅ ランダムフォレスト/XGBoost選択時:\n",
    "        • 適度な複雑さ\n",
    "        • 特徴量重要度が必要\n",
    "        • 非線形関係が存在\n",
    "        \n",
    "        ✅ ディープラーニング選択時:\n",
    "        • 大量のデータ\n",
    "        • 複雑なパターン\n",
    "        • 最高性能が必要\n",
    "        \"\"\"\n",
    "        axes[1, 1].text(0.1, 0.9, guide_text, transform=axes[1, 1].transAxes,\n",
    "                       fontsize=11, verticalalignment='top')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig('lesson3_architecture.png', dpi=150)\n",
    "        plt.show()\n",
    "        \n",
    "        print(\"\\n💡 重要なインサイト:\")\n",
    "        print(\"   • 複雑さ ↑ = 性能 ↑ しかし 解釈可能性 ↓\")\n",
    "        print(\"   • データサイズと問題の複雑さに応じて選択\")\n",
    "        print(\"   • ノーフリーランチ定理: すべての問題に最適なモデルは存在しない\")\n",
    "    \n",
    "    def lesson_4_training_comparison(self):\n",
    "        \"\"\"レッスン4: 学習プロセスの比較\"\"\"\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"📚 レッスン4: 学習プロセスの比較\")\n",
    "        print(\"=\"*80)\n",
    "        \n",
    "        # データ準備\n",
    "        from sklearn.linear_model import LinearRegression, Ridge\n",
    "        from sklearn.ensemble import RandomForestRegressor\n",
    "        \n",
    "        # 簡単な前処理\n",
    "        X = pd.get_dummies(self.df.drop('家賃_円', axis=1))\n",
    "        y = self.df['家賃_円'].values\n",
    "        \n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X, y, test_size=0.2, random_state=42\n",
    "        )\n",
    "        \n",
    "        scaler = StandardScaler()\n",
    "        X_train_scaled = scaler.fit_transform(X_train)\n",
    "        X_test_scaled = scaler.transform(X_test)\n",
    "        \n",
    "        # 学習曲線の比較\n",
    "        fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "        \n",
    "        models = {\n",
    "            '線形回帰': LinearRegression(),\n",
    "            'Ridge回帰': Ridge(alpha=10),\n",
    "            'ランダムフォレスト': RandomForestRegressor(n_estimators=50, random_state=42)\n",
    "        }\n",
    "        \n",
    "        for idx, (name, model) in enumerate(models.items()):\n",
    "            # 学習曲線\n",
    "            train_sizes, train_scores, val_scores = learning_curve(\n",
    "                model, X_train_scaled, y_train, cv=5,\n",
    "                train_sizes=np.linspace(0.1, 1.0, 10),\n",
    "                scoring='neg_mean_squared_error'\n",
    "            )\n",
    "            \n",
    "            ax = axes[idx//2, idx%2]\n",
    "            ax.plot(train_sizes, -train_scores.mean(axis=1), \n",
    "                   'o-', label='訓練', linewidth=2)\n",
    "            ax.plot(train_sizes, -val_scores.mean(axis=1), \n",
    "                   'o-', label='検証', linewidth=2)\n",
    "            ax.fill_between(train_sizes, \n",
    "                           -train_scores.mean(axis=1) - train_scores.std(axis=1),\n",
    "                           -train_scores.mean(axis=1) + train_scores.std(axis=1),\n",
    "                           alpha=0.1)\n",
    "            ax.fill_between(train_sizes,\n",
    "                           -val_scores.mean(axis=1) - val_scores.std(axis=1),\n",
    "                           -val_scores.mean(axis=1) + val_scores.std(axis=1),\n",
    "                           alpha=0.1)\n",
    "            \n",
    "            ax.set_xlabel('訓練サイズ')\n",
    "            ax.set_ylabel('MSE')\n",
    "            ax.set_title(f'{name}の学習曲線')\n",
    "            ax.legend()\n",
    "            ax.grid(True, alpha=0.3)\n",
    "        \n",
    "        # ディープラーニングの学習曲線（シミュレーション）\n",
    "        ax = axes[1, 1]\n",
    "        epochs = np.arange(1, 51)\n",
    "        train_loss = 50000 * np.exp(-epochs/15) + 10000\n",
    "        val_loss = 50000 * np.exp(-epochs/12) + 12000\n",
    "        \n",
    "        ax.plot(epochs, train_loss, label='訓練損失', linewidth=2)\n",
    "        ax.plot(epochs, val_loss, label='検証損失', linewidth=2)\n",
    "        ax.set_xlabel('エポック')\n",
    "        ax.set_ylabel('損失')\n",
    "        ax.set_title('ディープラーニングの学習進行')\n",
    "        ax.legend()\n",
    "        ax.grid(True, alpha=0.3)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig('lesson4_training.png', dpi=150)\n",
    "        plt.show()\n",
    "        \n",
    "        print(\"\\n🔧 機械学習の学習特徴:\")\n",
    "        print(\"   • 即座に収束（閉形式解）\")\n",
    "        print(\"   • ハイパーパラメータが少ない\")\n",
    "        print(\"   • クロスバリデーションで評価\")\n",
    "        \n",
    "        print(\"\\n🧠 ディープラーニングの学習特徴:\")\n",
    "        print(\"   • 反復的最適化（勾配降下法）\")\n",
    "        print(\"   • 多くのハイパーパラメータ\")\n",
    "        print(\"   • Early stopping、学習率スケジューリング\")\n",
    "        \n",
    "        print(\"\\n💡 過学習防止戦略:\")\n",
    "        print(\"   ML: 正則化（L1/L2）、木の深さ制限、アンサンブル\")\n",
    "        print(\"   DL: Dropout、Batch Norm、Weight Decay、データ拡張\")\n",
    "    \n",
    "    def lesson_5_performance_comparison(self):\n",
    "        \"\"\"レッスン5: 性能比較と解釈\"\"\"\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"📚 レッスン5: 性能比較と解釈\")\n",
    "        print(\"=\"*80)\n",
    "        \n",
    "        # 仮想的な性能データ（実際の学習結果をシミュレーション）\n",
    "        performance_data = {\n",
    "            'モデル': ['線形回帰', 'Ridge', 'Lasso', 'ランダムフォレスト', 'XGBoost', 'ニューラルネット'],\n",
    "            '訓練R2': [0.75, 0.74, 0.73, 0.95, 0.93, 0.96],\n",
    "            'テストR2': [0.72, 0.73, 0.72, 0.85, 0.87, 0.89],\n",
    "            'MAE': [15000, 14800, 15200, 11000, 10500, 9800],\n",
    "            'RMSE': [20000, 19500, 20200, 15000, 14000, 13000],\n",
    "            '学習時間_秒': [0.1, 0.1, 0.2, 2.5, 5.0, 30.0]\n",
    "        }\n",
    "        \n",
    "        df_perf = pd.DataFrame(performance_data)\n",
    "        \n",
    "        fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "        \n",
    "        # R²スコア比較\n",
    "        x = np.arange(len(df_perf['モデル']))\n",
    "        width = 0.35\n",
    "        \n",
    "        bars1 = axes[0, 0].bar(x - width/2, df_perf['訓練R2'], width, \n",
    "                               label='訓練', alpha=0.8)\n",
    "        bars2 = axes[0, 0].bar(x + width/2, df_perf['テストR2'], width, \n",
    "                               label='テスト', alpha=0.8)\n",
    "        axes[0, 0].set_xlabel('モデル')\n",
    "        axes[0, 0].set_ylabel('R²スコア')\n",
    "        axes[0, 0].set_title('R²スコア比較')\n",
    "        axes[0, 0].set_xticks(x)\n",
    "        axes[0, 0].set_xticklabels(df_perf['モデル'], rotation=45)\n",
    "        axes[0, 0].legend()\n",
    "        axes[0, 0].grid(True, alpha=0.3)\n",
    "        \n",
    "        # 誤差メトリクス\n",
    "        axes[0, 1].bar(df_perf['モデル'], df_perf['MAE'], alpha=0.7, \n",
    "                      label='MAE', color='blue')\n",
    "        axes[0, 1].set_xlabel('モデル')\n",
    "        axes[0, 1].set_ylabel('誤差（円）')\n",
    "        axes[0, 1].set_title('平均絶対誤差')\n",
    "        axes[0, 1].set_xticklabels(df_perf['モデル'], rotation=45)\n",
    "        axes[0, 1].grid(True, alpha=0.3)\n",
    "        \n",
    "        # 学習時間 vs 性能\n",
    "        axes[0, 2].scatter(df_perf['学習時間_秒'], df_perf['テストR2'], \n",
    "                          s=200, alpha=0.6, c=range(len(df_perf)), cmap='viridis')\n",
    "        for i, model in enumerate(df_perf['モデル']):\n",
    "            axes[0, 2].annotate(model, \n",
    "                               (df_perf['学習時間_秒'][i], \n",
    "                                df_perf['テストR2'][i]),\n",
    "                               fontsize=9)\n",
    "        axes[0, 2].set_xlabel('学習時間（秒）')\n",
    "        axes[0, 2].set_ylabel('テストR²')\n",
    "        axes[0, 2].set_title('効率性 vs 性能')\n",
    "        axes[0, 2].grid(True, alpha=0.3)\n",
    "        \n",
    "        # 過学習分析\n",
    "        overfitting = df_perf['訓練R2'] - df_perf['テストR2']\n",
    "        axes[1, 0].bar(df_perf['モデル'], overfitting, \n",
    "                      color=['green' if x < 0.05 else 'orange' if x < 0.1 else 'red' \n",
    "                             for x in overfitting])\n",
    "        axes[1, 0].set_xlabel('モデル')\n",
    "        axes[1, 0].set_ylabel('訓練R² - テストR²')\n",
    "        axes[1, 0].set_title('過学習分析')\n",
    "        axes[1, 0].axhline(y=0.1, color='r', linestyle='--', label='過学習閾値')\n",
    "        axes[1, 0].set_xticklabels(df_perf['モデル'], rotation=45)\n",
    "        axes[1, 0].legend()\n",
    "        axes[1, 0].grid(True, alpha=0.3)\n",
    "        \n",
    "        # 予測分布（シミュレーション）\n",
    "        np.random.seed(42)\n",
    "        true_values = np.random.normal(100000, 30000, 100)\n",
    "        \n",
    "        predictions = {\n",
    "            '線形回帰': true_values + np.random.normal(0, 20000, 100),\n",
    "            'ランダムフォレスト': true_values + np.random.normal(0, 15000, 100),\n",
    "            'ニューラルネット': true_values + np.random.normal(0, 10000, 100)\n",
    "        }\n",
    "        \n",
    "        for model_name, pred in predictions.items():\n",
    "            axes[1, 1].scatter(true_values, pred, alpha=0.5, label=model_name, s=20)\n",
    "        \n",
    "        axes[1, 1].plot([true_values.min(), true_values.max()], \n",
    "                       [true_values.min(), true_values.max()], \n",
    "                       'r--', label='完璧な予測')\n",
    "        axes[1, 1].set_xlabel('真値（円）')\n",
    "        axes[1, 1].set_ylabel('予測値（円）')\n",
    "        axes[1, 1].set_title('予測精度の比較')\n",
    "        axes[1, 1].legend()\n",
    "        axes[1, 1].grid(True, alpha=0.3)\n",
    "        \n",
    "        # 特徴量重要度（ランダムフォレストの例）\n",
    "        feature_importance = np.random.random(10) * 0.3\n",
    "        feature_importance[0] = 0.4  # 区が最も重要\n",
    "        feature_names = ['区', '部屋サイズ', '駅距離', '築年数', \n",
    "                        '建物構造', 'タイプ', '階数', '向き', \n",
    "                        '駐車場', 'ペット可']\n",
    "        \n",
    "        sorted_idx = np.argsort(feature_importance)[::-1]\n",
    "        axes[1, 2].barh(range(len(sorted_idx)), feature_importance[sorted_idx])\n",
    "        axes[1, 2].set_yticks(range(len(sorted_idx)))\n",
    "        axes[1, 2].set_yticklabels([feature_names[i] for i in sorted_idx])\n",
    "        axes[1, 2].set_xlabel('特徴量重要度')\n",
    "        axes[1, 2].set_title('特徴量重要度（ランダムフォレスト）')\n",
    "        axes[1, 2].grid(True, alpha=0.3)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig('lesson5_performance.png', dpi=150)\n",
    "        plt.show()\n",
    "        \n",
    "        print(\"\\n📊 性能サマリー:\")\n",
    "        for _, row in df_perf.iterrows():\n",
    "            print(f\"\\n{row['モデル']}:\")\n",
    "            print(f\"   テストR²: {row['テストR2']:.3f}\")\n",
    "            print(f\"   MAE: ¥{row['MAE']:,.0f}\")\n",
    "            print(f\"   過学習度: {row['訓練R2'] - row['テストR2']:.3f}\")\n",
    "        \n",
    "        print(\"\\n💡 重要なインサイト:\")\n",
    "        print(\"   1. 単純なモデル: 安定的、解釈容易、過学習少ない\")\n",
    "        print(\"   2. アンサンブルモデル: バランスの取れた性能\")\n",
    "        print(\"   3. ディープラーニング: 最高性能、過学習リスク、学習時間長い\")\n",
    "        \n",
    "    def lesson_6_practical_considerations(self):\n",
    "        \"\"\"レッスン6: 実践的な考慮事項\"\"\"\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"📚 レッスン6: 実践的な考慮事項\")\n",
    "        print(\"=\"*80)\n",
    "        \n",
    "        considerations = {\n",
    "            '評価基準': ['データサイズ', '学習時間', '予測時間', \n",
    "                        '解釈可能性', '特徴量エンジニアリング', 'ハイパーパラメータ調整',\n",
    "                        'ハードウェア要件', 'メンテナンス'],\n",
    "            '従来型ML': ['少量データでも動作', '高速', '非常に高速',\n",
    "                        '高い', '手動', '中程度',\n",
    "                        'CPU十分', '簡単'],\n",
    "            'ディープラーニング': ['大量データ必要', '低速', '高速',\n",
    "                                '低い（ブラックボックス）', '自動', '複雑',\n",
    "                                'GPU推奨', '複雑']\n",
    "        }\n",
    "        \n",
    "        df_consider = pd.DataFrame(considerations)\n",
    "        \n",
    "        print(\"\\n📋 意思決定チェックリスト:\")\n",
    "        print(\"\\n✅ 機械学習を選択すべき時:\")\n",
    "        print(\"   □ データが1万件未満\")\n",
    "        print(\"   □ 解釈可能性が重要（規制、医療、金融）\")\n",
    "        print(\"   □ 迅速なプロトタイピングが必要\")\n",
    "        print(\"   □ 限られたコンピューティングリソース\")\n",
    "        print(\"   □ リアルタイム予測が必要\")\n",
    "        \n",
    "        print(\"\\n✅ ディープラーニングを選択すべき時:\")\n",
    "        print(\"   □ 大量のデータ（10万件以上）\")\n",
    "        print(\"   □ 複雑な非線形パターン\")\n",
    "        print(\"   □ 画像、テキスト、音声データ\")\n",
    "        print(\"   □ 最高性能が目標\")\n",
    "        print(\"   □ GPUリソースが利用可能\")\n",
    "        \n",
    "        # コスト効果分析\n",
    "        fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "        \n",
    "        # データサイズ別性能\n",
    "        data_sizes = [100, 500, 1000, 5000, 10000, 50000, 100000]\n",
    "        ml_performance = [0.5, 0.65, 0.72, 0.78, 0.82, 0.84, 0.85]\n",
    "        dl_performance = [0.3, 0.45, 0.60, 0.75, 0.83, 0.88, 0.92]\n",
    "        \n",
    "        axes[0].plot(data_sizes, ml_performance, 'o-', label='従来型ML', linewidth=2)\n",
    "        axes[0].plot(data_sizes, dl_performance, 's-', label='ディープラーニング', linewidth=2)\n",
    "        axes[0].set_xscale('log')\n",
    "        axes[0].set_xlabel('訓練データサイズ')\n",
    "        axes[0].set_ylabel('モデル性能（R²）')\n",
    "        axes[0].set_title('性能 vs データサイズ')\n",
    "        axes[0].legend()\n",
    "        axes[0].grid(True, alpha=0.3)\n",
    "        axes[0].axvline(x=10000, color='red', linestyle='--', alpha=0.5)\n",
    "        axes[0].text(10000, 0.3, '交差点', rotation=90, va='bottom')\n",
    "        \n",
    "        # ROI分析\n",
    "        categories = ['開発\\n時間', '学習\\nコスト', '推論\\nコスト', \n",
    "                     'メンテナンス', '精度\\n向上']\n",
    "        ml_scores = [8, 9, 10, 8, 6]\n",
    "        dl_scores = [5, 4, 7, 5, 9]\n",
    "        \n",
    "        angles = np.linspace(0, 2*np.pi, len(categories), endpoint=False).tolist()\n",
    "        ml_scores += ml_scores[:1]\n",
    "        dl_scores += dl_scores[:1]\n",
    "        angles += angles[:1]\n",
    "        \n",
    "        ax = fig.add_subplot(122, projection='polar')\n",
    "        ax.plot(angles, ml_scores, 'o-', linewidth=2, label='従来型ML')\n",
    "        ax.fill(angles, ml_scores, alpha=0.25)\n",
    "        ax.plot(angles, dl_scores, 's-', linewidth=2, label='ディープラーニング')\n",
    "        ax.fill(angles, dl_scores, alpha=0.25)\n",
    "        ax.set_xticks(angles[:-1])\n",
    "        ax.set_xticklabels(categories)\n",
    "        ax.set_ylim(0, 10)\n",
    "        ax.set_title('コスト便益分析', pad=20)\n",
    "        ax.legend(loc='upper right', bbox_to_anchor=(1.3, 1.1))\n",
    "        ax.grid(True)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig('lesson6_practical.png', dpi=150)\n",
    "        plt.show()\n",
    "        \n",
    "        print(\"\\n💼 ビジネス観点:\")\n",
    "        print(\"   • MVP/POC: 機械学習で迅速に開始\")\n",
    "        print(\"   • スケールアップ: データ増加時にディープラーニング転換を検討\")\n",
    "        print(\"   • ハイブリッド: アンサンブルで両アプローチを組み合わせ\")\n",
    "        \n",
    "        print(\"\\n🎯 最終推奨事項:\")\n",
    "        print(\"   1. 常に簡単なモデルから開始（ベースライン）\")\n",
    "        print(\"   2. 段階的に複雑さを増加\")\n",
    "        print(\"   3. ビジネス要件を優先\")\n",
    "        print(\"   4. 技術的負債を考慮\")\n",
    "    \n",
    "    def create_quiz(self):\n",
    "        \"\"\"学習確認クイズ\"\"\"\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"🎯 学習確認クイズ\")\n",
    "        print(\"=\"*80)\n",
    "        \n",
    "        quiz = [\n",
    "            {\n",
    "                'question': \"Q1. カテゴリ変数が多い場合の機械学習の問題点は？\",\n",
    "                'options': [\"A. 次元の呪い\", \"B. 過学習\", \"C. 計算複雑性の増加\", \"D. すべて正しい\"],\n",
    "                'answer': \"D\",\n",
    "                'explanation': \"One-Hot Encodingによる次元増加、疎行列、過学習リスク\"\n",
    "            },\n",
    "            {\n",
    "                'question': \"Q2. ディープラーニングの埋め込み層の利点は？\",\n",
    "                'options': [\"A. 次元削減\", \"B. 意味的類似性の学習\", \"C. 自動特徴抽出\", \"D. すべて正しい\"],\n",
    "                'answer': \"D\",\n",
    "                'explanation': \"カテゴリを低次元密ベクトルで表現、類似カテゴリは近いベクトル\"\n",
    "            },\n",
    "            {\n",
    "                'question': \"Q3. データが1000件の時の最適選択は？\",\n",
    "                'options': [\"A. ディープラーニング\", \"B. ランダムフォレスト\", \"C. 線形回帰\", \"D. 状況による\"],\n",
    "                'answer': \"B\",\n",
    "                'explanation': \"適度な複雑さ、過学習防止、良好な性能のバランス\"\n",
    "            },\n",
    "            {\n",
    "                'question': \"Q4. 解釈可能性が最も重要なドメインは？\",\n",
    "                'options': [\"A. ゲームAI\", \"B. 医療診断\", \"C. 画像フィルター\", \"D. 音楽推薦\"],\n",
    "                'answer': \"B\",\n",
    "                'explanation': \"医療、金融、法律等では意思決定の根拠が重要\"\n",
    "            }\n",
    "        ]\n",
    "        \n",
    "        for q in quiz:\n",
    "            print(f\"\\n{q['question']}\")\n",
    "            for opt in q['options']:\n",
    "                print(f\"   {opt}\")\n",
    "            print(f\"\\n   正解: {q['answer']}\")\n",
    "            print(f\"   説明: {q['explanation']}\")\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"🏆 学習完了！\")\n",
    "        print(\"=\"*80)\n",
    "        print(\"\\n核心メッセージ:\")\n",
    "        print(\"• 銀の弾丸はない - 完璧なモデルは存在しない\")\n",
    "        print(\"• シンプルから始める - 簡単なものから開始\")\n",
    "        print(\"• データを知る - データ理解が最優先\")\n",
    "        print(\"• トレードオフのバランス - 性能 vs 解釈可能性 vs 効率性\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3d13949-8691-485b-8d86-354e80ed03f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"メイン教育プログラム実行\"\"\"\n",
    "system = MLvsDLEducationalSystem()\n",
    "\n",
    "# 全カリキュラム実行\n",
    "print(\"\\n🎓 機械学習 vs ディープラーニング総合教育プログラム開始\\n\")\n",
    "\n",
    "# レッスン1: データ理解\n",
    "input(\"Enterキーを押してレッスン1を開始...\")\n",
    "system.lesson_1_data_understanding()\n",
    "\n",
    "# レッスン2: 前処理比較\n",
    "input(\"\\nEnterキーを押してレッスン2へ進む...\")\n",
    "system.lesson_2_preprocessing_comparison()\n",
    "\n",
    "# レッスン3: モデルアーキテクチャ\n",
    "input(\"\\nEnterキーを押してレッスン3へ進む...\")\n",
    "system.lesson_3_model_architecture()\n",
    "\n",
    "# レッスン4: 学習プロセス\n",
    "input(\"\\nEnterキーを押してレッスン4へ進む...\")\n",
    "system.lesson_4_training_comparison()\n",
    "\n",
    "# レッスン5: 性能比較\n",
    "input(\"\\nEnterキーを押してレッスン5へ進む...\")\n",
    "system.lesson_5_performance_comparison()\n",
    "\n",
    "# レッスン6: 実践的な考慮事項\n",
    "input(\"\\nEnterキーを押してレッスン6へ進む...\")\n",
    "system.lesson_6_practical_considerations()\n",
    "\n",
    "# クイズ\n",
    "input(\"\\nEnterキーを押してクイズを開始...\")\n",
    "system.create_quiz()\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"📚 教育プログラム完了！\")\n",
    "print(\"=\"*80)\n",
    "print(\"\\n生成された資料:\")\n",
    "print(\"  • lesson1_data_understanding.png\")\n",
    "print(\"  • lesson2_preprocessing.png\")\n",
    "print(\"  • lesson3_architecture.png\")\n",
    "print(\"  • lesson4_training.png\")\n",
    "print(\"  • lesson5_performance.png\")\n",
    "print(\"  • lesson6_practical.png\")\n",
    "print(\"\\n次のステップ:\")\n",
    "print(\"  1. 実際のデータで直接実装してみる\")\n",
    "print(\"  2. ハイパーパラメータチューニング実習\")\n",
    "print(\"  3. アンサンブル手法の探求\")\n",
    "print(\"  4. AutoMLツールの活用\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_edu",
   "language": "python",
   "name": "env_edu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
