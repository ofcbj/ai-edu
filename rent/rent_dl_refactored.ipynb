{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ğŸ  æ±äº¬å®¶è³ƒäºˆæ¸¬ã‚·ã‚¹ãƒ†ãƒ  - ãƒ‡ã‚£ãƒ¼ãƒ—ãƒ©ãƒ¼ãƒ‹ãƒ³ã‚°ç‰ˆ v2\n",
    "\n",
    "**ã€æ”¹å–„ç‚¹ã€‘**\n",
    "- ã‚¯ãƒ©ã‚¹æ§‹é€ ã®æ•´ç†ã¨ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«åŒ–\n",
    "- å­¦ç¿’ãƒ»äºˆæ¸¬ãƒ­ã‚¸ãƒƒã‚¯ã®åˆ†é›¢\n",
    "- Webã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹çµ±åˆ\n",
    "- ã‚³ãƒ¼ãƒ‰é‡è¤‡å‰Šé™¤ã¨å¯èª­æ€§å‘ä¸Š"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚¤ãƒ³ãƒãƒ¼ãƒˆ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['font.family'] = ['Meiryo']\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "import matplotlib.font_manager as fmt\n",
    "fmt.fontManager.addfont(r'./meiryo.ttc')  # ç’°å¢ƒã«å¿œã˜ã¦ã‚³ãƒ¡ãƒ³ãƒˆè§£é™¤\n",
    "\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, HTML, clear_output\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"ä½¿ç”¨ãƒ‡ãƒã‚¤ã‚¹: {device}\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. ãƒ‡ãƒ¼ã‚¿å‰å‡¦ç†ã‚¯ãƒ©ã‚¹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RentDataPreprocessor:\n",
    "    \"\"\"ãƒ‡ã‚£ãƒ¼ãƒ—ãƒ©ãƒ¼ãƒ‹ãƒ³ã‚°ç”¨ãƒ‡ãƒ¼ã‚¿å‰å‡¦ç†ã‚¯ãƒ©ã‚¹\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.scaler = StandardScaler()\n",
    "        self.label_encoders = {}\n",
    "        self.num_wards = 0\n",
    "        self.num_structures = 0\n",
    "        self.num_types = 0\n",
    "        self.ward_avg_price_dict = {}  # âœ… åŒºåˆ¥å¹³å‡ä¾¡æ ¼ã‚’ä¿å­˜\n",
    "        \n",
    "    def fit_transform(self, df):\n",
    "        \"\"\"ãƒ‡ãƒ¼ã‚¿å‰å‡¦ç†ã¨å¤‰æ›ï¼ˆå­¦ç¿’æ™‚ï¼‰\"\"\"\n",
    "        df_processed = df.copy()\n",
    "        \n",
    "        # 1. ã‚«ãƒ†ã‚´ãƒªå¤‰æ•°ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°\n",
    "        self.label_encoders['åŒº'] = LabelEncoder()\n",
    "        df_processed['åŒº_encoded'] = self.label_encoders['åŒº'].fit_transform(df['åŒº'])\n",
    "        self.num_wards = len(df['åŒº'].unique())\n",
    "        \n",
    "        for col in ['å»ºç‰©æ§‹é€ ', 'å»ºç‰©ã‚¿ã‚¤ãƒ—']:\n",
    "            self.label_encoders[col] = LabelEncoder()\n",
    "            df_processed[f'{col}_encoded'] = self.label_encoders[col].fit_transform(df[col])\n",
    "        \n",
    "        self.num_structures = len(df['å»ºç‰©æ§‹é€ '].unique())\n",
    "        self.num_types = len(df['å»ºç‰©ã‚¿ã‚¤ãƒ—'].unique())\n",
    "        \n",
    "        # 2. æ•°å€¤å¤‰æ•°ã®æ­£è¦åŒ–\n",
    "        numeric_cols = ['éƒ¨å±‹ã‚µã‚¤ã‚º_m2', 'é§…è·é›¢_åˆ†', 'ç¯‰å¹´æ•°_å¹´']\n",
    "        df_processed[numeric_cols] = self.scaler.fit_transform(df[numeric_cols])\n",
    "        \n",
    "        # 3. åŒºåˆ¥å¹³å‡ä¾¡æ ¼ï¼ˆè£œåŠ©ç‰¹å¾´é‡ï¼‰\n",
    "        ward_avg_price = df.groupby('åŒº')['å®¶è³ƒ_å††'].mean()\n",
    "        self.ward_avg_price_dict = ward_avg_price.to_dict()  # âœ… ä¿å­˜\n",
    "        \n",
    "        df_processed['åŒº_avg_price'] = df['åŒº'].map(ward_avg_price)\n",
    "        \n",
    "        # æ­£è¦åŒ–ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’ä¿å­˜\n",
    "        self.ward_avg_price_mean = df_processed['åŒº_avg_price'].mean()\n",
    "        self.ward_avg_price_std = df_processed['åŒº_avg_price'].std()\n",
    "        \n",
    "        df_processed['åŒº_avg_price'] = (\n",
    "            (df_processed['åŒº_avg_price'] - self.ward_avg_price_mean) / \n",
    "            self.ward_avg_price_std\n",
    "        )\n",
    "        \n",
    "        return df_processed\n",
    "    \n",
    "    def transform(self, df):\n",
    "        \"\"\"å­¦ç¿’æ¸ˆã¿å‰å‡¦ç†å™¨ã§å¤‰æ›ï¼ˆäºˆæ¸¬æ™‚ï¼‰\"\"\"\n",
    "        df_processed = df.copy()\n",
    "        \n",
    "        # ã‚«ãƒ†ã‚´ãƒªå¤‰æ•°ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°\n",
    "        df_processed['åŒº_encoded'] = self.label_encoders['åŒº'].transform(df['åŒº'])\n",
    "        \n",
    "        for col in ['å»ºç‰©æ§‹é€ ', 'å»ºç‰©ã‚¿ã‚¤ãƒ—']:\n",
    "            df_processed[f'{col}_encoded'] = self.label_encoders[col].transform(df[col])\n",
    "        \n",
    "        # æ•°å€¤å¤‰æ•°ã®æ­£è¦åŒ–\n",
    "        numeric_cols = ['éƒ¨å±‹ã‚µã‚¤ã‚º_m2', 'é§…è·é›¢_åˆ†', 'ç¯‰å¹´æ•°_å¹´']\n",
    "        df_processed[numeric_cols] = self.scaler.transform(df[numeric_cols])\n",
    "        \n",
    "        # âœ… åŒºåˆ¥å¹³å‡ä¾¡æ ¼ã‚’è¿½åŠ ï¼ˆå­¦ç¿’æ™‚ã¨åŒã˜æ­£è¦åŒ–ï¼‰\n",
    "        df_processed['åŒº_avg_price'] = df['åŒº'].map(self.ward_avg_price_dict)\n",
    "        df_processed['åŒº_avg_price'] = (\n",
    "            (df_processed['åŒº_avg_price'] - self.ward_avg_price_mean) / \n",
    "            self.ward_avg_price_std\n",
    "        )\n",
    "        \n",
    "        return df_processed\n",
    "\n",
    "\n",
    "class TokyoRentDataset(Dataset):\n",
    "    \"\"\"PyTorch Dataset for Tokyo Rent Data\"\"\"\n",
    "    \n",
    "    def __init__(self, features, targets):\n",
    "        self.features = torch.FloatTensor(features)\n",
    "        self.targets = torch.FloatTensor(targets)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.features)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.features[idx], self.targets[idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. ãƒ‡ã‚£ãƒ¼ãƒ—ãƒ©ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ¢ãƒ‡ãƒ«å®šç¾©"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RentPredictionNetWithAttention(nn.Module):\n",
    "    \"\"\"Attentionãƒ¡ã‚«ãƒ‹ã‚ºãƒ ã‚’å«ã‚€ãƒ‡ã‚£ãƒ¼ãƒ—ãƒ©ãƒ¼ãƒ‹ãƒ³ã‚°å®¶è³ƒäºˆæ¸¬ãƒ¢ãƒ‡ãƒ«\"\"\"\n",
    "    \n",
    "    def __init__(self, num_wards, num_structures, num_types, \n",
    "                 embedding_dim=32, hidden_dims=[512, 256, 128]):\n",
    "        super(RentPredictionNetWithAttention, self).__init__()\n",
    "        \n",
    "        # åŸ‹ã‚è¾¼ã¿å±¤\n",
    "        self.ward_embedding = nn.Embedding(num_wards, embedding_dim)\n",
    "        self.structure_embedding = nn.Embedding(num_structures, embedding_dim // 2)\n",
    "        self.type_embedding = nn.Embedding(num_types, embedding_dim // 2)\n",
    "        \n",
    "        # Attentionãƒ¡ã‚«ãƒ‹ã‚ºãƒ \n",
    "        self.attention = nn.Sequential(\n",
    "            nn.Linear(embedding_dim, embedding_dim // 2),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(embedding_dim // 2, 1),\n",
    "            nn.Softmax(dim=1)\n",
    "        )\n",
    "        \n",
    "        # äº¤äº’ä½œç”¨å±¤\n",
    "        self.ward_room_interaction = nn.Linear(embedding_dim + 1, embedding_dim)\n",
    "        self.ward_station_interaction = nn.Linear(embedding_dim + 1, embedding_dim)\n",
    "        \n",
    "        # å…¥åŠ›æ¬¡å…ƒè¨ˆç®—\n",
    "        input_dim = 3 + embedding_dim * 3 + (embedding_dim // 2) * 2 + 1\n",
    "        \n",
    "        # ãƒ¡ã‚¤ãƒ³ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯\n",
    "        layers = []\n",
    "        prev_dim = input_dim\n",
    "        \n",
    "        for hidden_dim in hidden_dims:\n",
    "            layers.extend([\n",
    "                nn.Linear(prev_dim, hidden_dim),\n",
    "                nn.BatchNorm1d(hidden_dim),\n",
    "                nn.LeakyReLU(0.1),\n",
    "                nn.Dropout(0.25)\n",
    "            ])\n",
    "            prev_dim = hidden_dim\n",
    "        \n",
    "        # Residualæ¥ç¶š\n",
    "        self.skip_connection = nn.Linear(input_dim, hidden_dims[-1])\n",
    "        \n",
    "        # å‡ºåŠ›å±¤\n",
    "        self.output_layer = nn.Sequential(\n",
    "            nn.Linear(hidden_dims[-1], hidden_dims[-1] // 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dims[-1] // 2, 1)\n",
    "        )\n",
    "        \n",
    "        self.network = nn.Sequential(*layers)\n",
    "        self._initialize_weights()\n",
    "    \n",
    "    def _initialize_weights(self):\n",
    "        \"\"\"é‡ã¿åˆæœŸåŒ–\"\"\"\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0)\n",
    "    \n",
    "    def forward(self, ward_idx, structure_idx, type_idx, numeric_features, ward_avg_price):\n",
    "        \"\"\"é †ä¼æ’­\"\"\"\n",
    "        # åŸ‹ã‚è¾¼ã¿\n",
    "        ward_emb = self.ward_embedding(ward_idx)\n",
    "        structure_emb = self.structure_embedding(structure_idx)\n",
    "        type_emb = self.type_embedding(type_idx)\n",
    "        \n",
    "        # Attentioné©ç”¨\n",
    "        attention_weights = self.attention(ward_emb)\n",
    "        ward_emb_attended = ward_emb * attention_weights\n",
    "        \n",
    "        # äº¤äº’ä½œç”¨ç‰¹å¾´é‡ç”Ÿæˆ\n",
    "        room_size = numeric_features[:, 0:1]\n",
    "        station_dist = numeric_features[:, 1:2]\n",
    "        \n",
    "        ward_room_feat = self.ward_room_interaction(torch.cat([ward_emb, room_size], dim=1))\n",
    "        ward_station_feat = self.ward_station_interaction(torch.cat([ward_emb, station_dist], dim=1))\n",
    "        \n",
    "        # å…¨ç‰¹å¾´é‡çµåˆ\n",
    "        features = torch.cat([\n",
    "            numeric_features,\n",
    "            ward_emb_attended,\n",
    "            ward_room_feat,\n",
    "            ward_station_feat,\n",
    "            structure_emb,\n",
    "            type_emb,\n",
    "            ward_avg_price.unsqueeze(1)\n",
    "        ], dim=1)\n",
    "        \n",
    "        # ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ + Residual\n",
    "        main_output = self.network(features)\n",
    "        skip_output = self.skip_connection(features)\n",
    "        combined = main_output + skip_output * 0.1\n",
    "        \n",
    "        output = self.output_layer(combined)\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. å­¦ç¿’ãƒ»è©•ä¾¡é–¢æ•°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, val_loader, num_epochs=100, learning_rate=0.001):\n",
    "    \"\"\"ãƒ¢ãƒ‡ãƒ«å­¦ç¿’\"\"\"\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=0.01)\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=10, factor=0.5)\n",
    "    \n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    best_val_loss = float('inf')\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        # Training\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        for batch_features, batch_targets in train_loader:\n",
    "            batch_features = batch_features.to(device)\n",
    "            batch_targets = batch_targets.to(device)\n",
    "            \n",
    "            # ç‰¹å¾´é‡åˆ†é›¢\n",
    "            ward_idx = batch_features[:, 0].long()\n",
    "            structure_idx = batch_features[:, 1].long()\n",
    "            type_idx = batch_features[:, 2].long()\n",
    "            numeric_features = batch_features[:, 3:6]\n",
    "            ward_avg_price = batch_features[:, 6]\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(ward_idx, structure_idx, type_idx, numeric_features, ward_avg_price)\n",
    "            loss = criterion(outputs.squeeze(), batch_targets)\n",
    "            loss.backward()\n",
    "            \n",
    "            # å‹¾é…ã‚¯ãƒªãƒƒãƒ”ãƒ³ã‚°\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "            \n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "        \n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for batch_features, batch_targets in val_loader:\n",
    "                batch_features = batch_features.to(device)\n",
    "                batch_targets = batch_targets.to(device)\n",
    "                \n",
    "                ward_idx = batch_features[:, 0].long()\n",
    "                structure_idx = batch_features[:, 1].long()\n",
    "                type_idx = batch_features[:, 2].long()\n",
    "                numeric_features = batch_features[:, 3:6]\n",
    "                ward_avg_price = batch_features[:, 6]\n",
    "                \n",
    "                outputs = model(ward_idx, structure_idx, type_idx, numeric_features, ward_avg_price)\n",
    "                loss = criterion(outputs.squeeze(), batch_targets)\n",
    "                val_loss += loss.item()\n",
    "        \n",
    "        avg_train_loss = train_loss / len(train_loader)\n",
    "        avg_val_loss = val_loss / len(val_loader)\n",
    "        train_losses.append(avg_train_loss)\n",
    "        val_losses.append(avg_val_loss)\n",
    "        \n",
    "        scheduler.step(avg_val_loss)\n",
    "        \n",
    "        # æœ€è‰¯ãƒ¢ãƒ‡ãƒ«ä¿å­˜\n",
    "        if avg_val_loss < best_val_loss:\n",
    "            best_val_loss = avg_val_loss\n",
    "            torch.save(model.state_dict(), 'best_rent_dl_model.pth')\n",
    "        \n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            print(f'Epoch [{epoch+1}/{num_epochs}], '\n",
    "                  f'Train Loss: {avg_train_loss:.4f}, Val Loss: {avg_val_loss:.4f}')\n",
    "    \n",
    "    return train_losses, val_losses\n",
    "\n",
    "\n",
    "def evaluate_model(model, test_loader):\n",
    "    \"\"\"ãƒ¢ãƒ‡ãƒ«è©•ä¾¡\"\"\"\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    actuals = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch_features, batch_targets in test_loader:\n",
    "            batch_features = batch_features.to(device)\n",
    "            \n",
    "            ward_idx = batch_features[:, 0].long()\n",
    "            structure_idx = batch_features[:, 1].long()\n",
    "            type_idx = batch_features[:, 2].long()\n",
    "            numeric_features = batch_features[:, 3:6]\n",
    "            ward_avg_price = batch_features[:, 6]\n",
    "            \n",
    "            outputs = model(ward_idx, structure_idx, type_idx, numeric_features, ward_avg_price)\n",
    "            predictions.extend(outputs.cpu().numpy().flatten() * 10000)\n",
    "            actuals.extend(batch_targets.numpy() * 10000)\n",
    "    \n",
    "    predictions = np.array(predictions)\n",
    "    actuals = np.array(actuals)\n",
    "    \n",
    "    # æ€§èƒ½æŒ‡æ¨™\n",
    "    mae = np.mean(np.abs(predictions - actuals))\n",
    "    rmse = np.sqrt(np.mean((predictions - actuals) ** 2))\n",
    "    r2 = 1 - (np.sum((actuals - predictions) ** 2) / np.sum((actuals - np.mean(actuals)) ** 2))\n",
    "    \n",
    "    return predictions, actuals, {'mae': mae, 'rmse': rmse, 'r2': r2}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œï¼šãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ‰ãƒ»å­¦ç¿’ãƒ»è©•ä¾¡"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"ğŸ  æ±äº¬å®¶è³ƒäºˆæ¸¬ã‚·ã‚¹ãƒ†ãƒ  - ãƒ‡ã‚£ãƒ¼ãƒ—ãƒ©ãƒ¼ãƒ‹ãƒ³ã‚°ç‰ˆ\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# 1. ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ‰\n",
    "print(\"\\n1. ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ‰\")\n",
    "df = pd.read_csv('tokyo_rent_data_v2.csv')\n",
    "print(f\"  ãƒ‡ãƒ¼ã‚¿æ•°: {len(df)}\")\n",
    "\n",
    "# 2. å‰å‡¦ç†\n",
    "print(\"\\n2. ãƒ‡ãƒ¼ã‚¿å‰å‡¦ç†\")\n",
    "preprocessor = RentDataPreprocessor()\n",
    "df_processed = preprocessor.fit_transform(df)\n",
    "\n",
    "# 3. ç‰¹å¾´é‡ãƒ»ã‚¿ãƒ¼ã‚²ãƒƒãƒˆåˆ†é›¢\n",
    "feature_cols = ['åŒº_encoded', 'å»ºç‰©æ§‹é€ _encoded', 'å»ºç‰©ã‚¿ã‚¤ãƒ—_encoded',\n",
    "                'éƒ¨å±‹ã‚µã‚¤ã‚º_m2', 'é§…è·é›¢_åˆ†', 'ç¯‰å¹´æ•°_å¹´', 'åŒº_avg_price']\n",
    "\n",
    "X = df_processed[feature_cols].values\n",
    "y = df['å®¶è³ƒ_å††'].values / 10000  # ä¸‡å˜ä½ã§ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°\n",
    "\n",
    "# 4. ãƒ‡ãƒ¼ã‚¿åˆ†å‰²\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "print(f\"  è¨“ç·´ãƒ‡ãƒ¼ã‚¿: {len(X_train)}\")\n",
    "print(f\"  æ¤œè¨¼ãƒ‡ãƒ¼ã‚¿: {len(X_val)}\")\n",
    "print(f\"  ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿: {len(X_test)}\")\n",
    "\n",
    "# 5. DataLoaderç”Ÿæˆ\n",
    "train_dataset = TokyoRentDataset(X_train, y_train)\n",
    "val_dataset = TokyoRentDataset(X_val, y_val)\n",
    "test_dataset = TokyoRentDataset(X_test, y_test)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# 6. ãƒ¢ãƒ‡ãƒ«æ§‹ç¯‰\n",
    "print(\"\\n3. ãƒ¢ãƒ‡ãƒ«æ§‹ç¯‰\")\n",
    "model = RentPredictionNetWithAttention(\n",
    "    preprocessor.num_wards, \n",
    "    preprocessor.num_structures, \n",
    "    preprocessor.num_types\n",
    ").to(device)\n",
    "\n",
    "print(f\"  ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "\n",
    "# 7. å­¦ç¿’\n",
    "print(\"\\n4. ãƒ¢ãƒ‡ãƒ«å­¦ç¿’é–‹å§‹\")\n",
    "train_losses, val_losses = train_model(model, train_loader, val_loader, num_epochs=50)\n",
    "\n",
    "# 8. è©•ä¾¡\n",
    "print(\"\\n5. ãƒ¢ãƒ‡ãƒ«è©•ä¾¡\")\n",
    "model.load_state_dict(torch.load('best_rent_dl_model.pth', map_location=device, weights_only=True))\n",
    "predictions, actuals, metrics = evaluate_model(model, test_loader)\n",
    "\n",
    "print(f\"  MAE: Â¥{metrics['mae']:,.0f}\")\n",
    "print(f\"  RMSE: Â¥{metrics['rmse']:,.0f}\")\n",
    "print(f\"  RÂ² Score: {metrics['r2']:.4f}\")\n",
    "\n",
    "# 9. ãƒ¢ãƒ‡ãƒ«ä¿å­˜\n",
    "torch.save({\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'preprocessor': preprocessor,\n",
    "    'model_config': {\n",
    "        'num_wards': preprocessor.num_wards,\n",
    "        'num_structures': preprocessor.num_structures,\n",
    "        'num_types': preprocessor.num_types\n",
    "    },\n",
    "    'metrics': metrics\n",
    "}, 'rent_dl_model_complete.pth')\n",
    "\n",
    "print(\"\\nâœ… ãƒ¢ãƒ‡ãƒ«ä¿å­˜å®Œäº†: rent_dl_model_complete.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. çµæœå¯è¦–åŒ–"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "\n",
    "# 1. å­¦ç¿’æ›²ç·š\n",
    "axes[0, 0].plot(train_losses, label='Train Loss', alpha=0.7)\n",
    "axes[0, 0].plot(val_losses, label='Validation Loss', alpha=0.7)\n",
    "axes[0, 0].set_xlabel('Epoch')\n",
    "axes[0, 0].set_ylabel('Loss')\n",
    "axes[0, 0].set_title('å­¦ç¿’å±¥æ­´')\n",
    "axes[0, 0].legend()\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# 2. äºˆæ¸¬ vs å®Ÿæ¸¬å€¤\n",
    "axes[0, 1].scatter(actuals, predictions, alpha=0.5)\n",
    "axes[0, 1].plot([actuals.min(), actuals.max()], [actuals.min(), actuals.max()], 'r--', lw=2)\n",
    "axes[0, 1].set_xlabel('å®Ÿæ¸¬å®¶è³ƒ (Â¥)')\n",
    "axes[0, 1].set_ylabel('äºˆæ¸¬å®¶è³ƒ (Â¥)')\n",
    "axes[0, 1].set_title(f'äºˆæ¸¬ vs å®Ÿæ¸¬ (RÂ² = {metrics[\"r2\"]:.4f})')\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# 3. æ®‹å·®ãƒ—ãƒ­ãƒƒãƒˆ\n",
    "residuals = actuals - predictions\n",
    "axes[1, 0].scatter(predictions, residuals, alpha=0.5)\n",
    "axes[1, 0].axhline(y=0, color='r', linestyle='--', lw=2)\n",
    "axes[1, 0].set_xlabel('äºˆæ¸¬å®¶è³ƒ (Â¥)')\n",
    "axes[1, 0].set_ylabel('æ®‹å·® (Â¥)')\n",
    "axes[1, 0].set_title('æ®‹å·®ãƒ—ãƒ­ãƒƒãƒˆ')\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# 4. åŒºåŸ‹ã‚è¾¼ã¿å¯è¦–åŒ–ï¼ˆPCAï¼‰\n",
    "ward_embeddings = model.ward_embedding.weight.detach().cpu().numpy()\n",
    "ward_names = preprocessor.label_encoders['åŒº'].classes_\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "ward_embeddings_2d = pca.fit_transform(ward_embeddings)\n",
    "\n",
    "ward_avg_prices = df.groupby('åŒº')['å®¶è³ƒ_å††'].mean()\n",
    "colors = [ward_avg_prices[ward] for ward in ward_names]\n",
    "\n",
    "scatter = axes[1, 1].scatter(ward_embeddings_2d[:, 0], ward_embeddings_2d[:, 1], \n",
    "                             c=colors, cmap='RdYlBu_r', s=100, alpha=0.7)\n",
    "\n",
    "for i, ward in enumerate(ward_names):\n",
    "    if ward in ['æ¸¯åŒº', 'åƒä»£ç”°åŒº', 'æ¸‹è°·åŒº', 'è¶³ç«‹åŒº', 'è‘›é£¾åŒº']:\n",
    "        axes[1, 1].annotate(ward, (ward_embeddings_2d[i, 0], ward_embeddings_2d[i, 1]),\n",
    "                          fontsize=9, ha='center')\n",
    "\n",
    "axes[1, 1].set_xlabel('åŸ‹ã‚è¾¼ã¿æ¬¡å…ƒ 1')\n",
    "axes[1, 1].set_ylabel('åŸ‹ã‚è¾¼ã¿æ¬¡å…ƒ 2')\n",
    "axes[1, 1].set_title('åŒºåŸ‹ã‚è¾¼ã¿ã®å¯è¦–åŒ–')\n",
    "plt.colorbar(scatter, ax=axes[1, 1], label='å¹³å‡å®¶è³ƒ')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('deep_learning_results.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"âœ… å¯è¦–åŒ–å®Œäº†: deep_learning_results.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–äºˆæ¸¬ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ãƒ¢ãƒ‡ãƒ«ãƒ­ãƒ¼ãƒ‰\n",
    "checkpoint = torch.load('rent_dl_model_complete.pth', map_location=device, weights_only=False)\n",
    "model_loaded = RentPredictionNetWithAttention(\n",
    "    checkpoint['model_config']['num_wards'],\n",
    "    checkpoint['model_config']['num_structures'],\n",
    "    checkpoint['model_config']['num_types']\n",
    ").to(device)\n",
    "model_loaded.load_state_dict(checkpoint['model_state_dict'])\n",
    "model_loaded.eval()\n",
    "\n",
    "preprocessor_loaded = checkpoint['preprocessor']\n",
    "\n",
    "# UIä½œæˆ\n",
    "ward_list = sorted(preprocessor_loaded.label_encoders['åŒº'].classes_)\n",
    "structure_list = sorted(preprocessor_loaded.label_encoders['å»ºç‰©æ§‹é€ '].classes_)\n",
    "type_list = sorted(preprocessor_loaded.label_encoders['å»ºç‰©ã‚¿ã‚¤ãƒ—'].classes_)\n",
    "\n",
    "ward_dropdown = widgets.Dropdown(options=ward_list, value='æ–°å®¿åŒº', description='åŒº:')\n",
    "room_slider = widgets.IntSlider(value=30, min=15, max=100, step=5, description='éƒ¨å±‹ã‚µã‚¤ã‚º(mÂ²):')\n",
    "station_slider = widgets.IntSlider(value=5, min=1, max=20, step=1, description='é§…è·é›¢(åˆ†):')\n",
    "age_slider = widgets.IntSlider(value=10, min=0, max=50, step=1, description='ç¯‰å¹´æ•°(å¹´):')\n",
    "structure_dropdown = widgets.Dropdown(options=structure_list, value='RCé€ ', description='å»ºç‰©æ§‹é€ :')\n",
    "type_dropdown = widgets.Dropdown(options=type_list, value='ãƒãƒ³ã‚·ãƒ§ãƒ³', description='å»ºç‰©ã‚¿ã‚¤ãƒ—:')\n",
    "predict_button = widgets.Button(description='ğŸ”® å®¶è³ƒäºˆæ¸¬', button_style='success')\n",
    "output_area = widgets.Output()\n",
    "\n",
    "def predict_rent(b):\n",
    "    \"\"\"äºˆæ¸¬å®Ÿè¡Œ\"\"\"\n",
    "    with output_area:\n",
    "        output_area.clear_output()\n",
    "        \n",
    "        # å…¥åŠ›ãƒ‡ãƒ¼ã‚¿ä½œæˆ\n",
    "        test_df = pd.DataFrame([{\n",
    "            'åŒº': ward_dropdown.value,\n",
    "            'å»ºç‰©æ§‹é€ ': structure_dropdown.value,\n",
    "            'å»ºç‰©ã‚¿ã‚¤ãƒ—': type_dropdown.value,\n",
    "            'éƒ¨å±‹ã‚µã‚¤ã‚º_m2': room_slider.value,\n",
    "            'é§…è·é›¢_åˆ†': station_slider.value,\n",
    "            'ç¯‰å¹´æ•°_å¹´': age_slider.value\n",
    "        }])\n",
    "        \n",
    "        # å‰å‡¦ç†\n",
    "        test_processed = preprocessor_loaded.transform(test_df)\n",
    "        \n",
    "        # ç‰¹å¾´é‡æŠ½å‡º\n",
    "        features = torch.FloatTensor(test_processed[feature_cols].values).to(device)\n",
    "        \n",
    "        # äºˆæ¸¬\n",
    "        with torch.no_grad():\n",
    "            ward_idx = features[:, 0].long()\n",
    "            structure_idx = features[:, 1].long()\n",
    "            type_idx = features[:, 2].long()\n",
    "            numeric_features = features[:, 3:6]\n",
    "            ward_avg_price = features[:, 6]\n",
    "            \n",
    "            prediction = model_loaded(ward_idx, structure_idx, type_idx, \n",
    "                                    numeric_features, ward_avg_price)\n",
    "            predicted_rent = prediction.item() * 10000\n",
    "        \n",
    "        # çµæœè¡¨ç¤º\n",
    "        html_output = f\"\"\"\n",
    "        <div style=\"background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); \n",
    "                    border-radius: 15px; padding: 25px; color: white;\">\n",
    "            <h2 style=\"margin: 0 0 20px 0;\">ğŸ  äºˆæ¸¬çµæœ</h2>\n",
    "            <div style=\"background: rgba(255,255,255,0.1); padding: 15px; border-radius: 10px;\">\n",
    "                <p><strong>åŒº:</strong> {ward_dropdown.value}</p>\n",
    "                <p><strong>éƒ¨å±‹ã‚µã‚¤ã‚º:</strong> {room_slider.value} mÂ²</p>\n",
    "                <p><strong>é§…è·é›¢:</strong> å¾’æ­©{station_slider.value}åˆ†</p>\n",
    "                <p><strong>ç¯‰å¹´æ•°:</strong> {age_slider.value}å¹´</p>\n",
    "                <p><strong>å»ºç‰©æ§‹é€ :</strong> {structure_dropdown.value}</p>\n",
    "                <p><strong>å»ºç‰©ã‚¿ã‚¤ãƒ—:</strong> {type_dropdown.value}</p>\n",
    "            </div>\n",
    "            <div style=\"background: white; color: #667eea; padding: 20px; \n",
    "                        border-radius: 10px; margin-top: 20px; text-align: center;\">\n",
    "                <div style=\"font-size: 14px;\">äºˆæ¸¬æœˆé¡å®¶è³ƒ</div>\n",
    "                <div style=\"font-size: 48px; font-weight: bold; margin: 10px 0;\">\n",
    "                    Â¥{predicted_rent:,.0f}\n",
    "                </div>\n",
    "                <div style=\"font-size: 12px; color: #999;\">ãƒ‡ã‚£ãƒ¼ãƒ—ãƒ©ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ¢ãƒ‡ãƒ«ä½¿ç”¨</div>\n",
    "            </div>\n",
    "        </div>\n",
    "        \"\"\"\n",
    "        display(HTML(html_output))\n",
    "\n",
    "predict_button.on_click(predict_rent)\n",
    "\n",
    "# UIãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆ\n",
    "ui = widgets.VBox([\n",
    "    widgets.HTML(\"<h2 style='color: #667eea;'>ğŸ  æ±äº¬å®¶è³ƒäºˆæ¸¬ã‚·ã‚¹ãƒ†ãƒ ï¼ˆãƒ‡ã‚£ãƒ¼ãƒ—ãƒ©ãƒ¼ãƒ‹ãƒ³ã‚°ï¼‰</h2>\"),\n",
    "    ward_dropdown,\n",
    "    room_slider,\n",
    "    station_slider,\n",
    "    age_slider,\n",
    "    structure_dropdown,\n",
    "    type_dropdown,\n",
    "    predict_button,\n",
    "    output_area\n",
    "])\n",
    "\n",
    "display(ui)\n",
    "\n",
    "print(\"\\nğŸš€ ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹æº–å‚™å®Œäº†ï¼\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
